services:
  ##################### POSTGRES PGADMIN############################
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      FOREX_ASSETS: ${FOREX_ASSETS}
      CRYPTO_ASSETS: ${CRYPTO_ASSETS}
      DATABASE: ${DATABASE}
    ports:
      - "${HOST_POSTGRES_PORT}:${POSTGRES_PORT}"
    volumes:
      - ./docker_init/postgres_init:/docker-entrypoint-initdb.d
      - ./docker_volume/postgres_data:/var/lib/postgresql/data
    logging:
      driver: none
    networks:
      - net
  ###################################################################
  pgadmin:
    image: dpage/pgadmin4:latest
    ports:
      - "${HOST_PGADMIN_PORT}:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD}
      PGADMIN_CONFIG_SERVER_MODE: "False"
      PGADMIN_CONFIG_MASTER_PASSWORD_REQUIRED: "False"
    command: ["./wait-for-it.sh", "postgres:5432", "--", "pgadmin4"]
    volumes:
      - ./docker_init/pgadmin_init/servers.json:/pgadmin4/servers.json
      - ./docker_init/pgadmin_init/wait-for-it.sh:/wait-for-it.sh
      - ./docker_init/pgadmin_init/.pgpass:/.pgpass
    user: "root"

    networks:
      - net
    depends_on:
      - postgres
    logging:
      driver: none
  # #################### END POSTGRES PGADMIN############################

  # #################### PREFECT SERVER ################################
  perfect_server:
    build:
      context: ./perfect_server
      dockerfile: Dockerfile
    environment:
      PREFECT_API_DATABASE_CONNECTION_URL: "postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/prefect"
      PREFECT_SERVER_API_HOST: "0.0.0.0"
      PREFECT_API_URL: "http://0.0.0.0:4200/api"
      POSTGRES_HOST: "postgres"
      POSTGRES_PORT: "5432"
    volumes:
      - ./perfect_server:/app
    ports:
      - "${PERFECT_PORT}:${PERFECT_PORT}"
    depends_on:
      - postgres
    networks:
      - net
    logging:
      driver: none
  # #################### END PREFECT SERVER ################################

  # #################### FASTAPI APP ################################
  # # fastapi-app:
  # #   build:
  # #     context: ./endpoint
  # #     dockerfile: Dockerfile
  # #   networks:
  # #     - cryptic_network
  # #   ports:
  # #     - "8000:8000"
  # #   volumes:
  # #     - ./endpoint:/code
  # #   # environment:
  # #   # - MODULE_NAME=app.main
  # #   command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  # ######################### KAFKA ################################
  timescaledb:
    image: timescale/timescaledb:latest-pg12
    ports:
      - "${HOST_TIMESCALE_PORT}:${LOCAL_TIMESCALE_PORT}"
    environment:
      POSTGRES_DB: ${TIMESCALE_DATABASE}
      POSTGRES_USER: ${TIMESCALE_USER}
      POSTGRES_PASSWORD: ${TIMESCALE_PASSWORD}
    volumes:
      - ./docker_volume/timescaledb_data:/var/lib/postgresql/data
    networks:
      - net
    logging:
      driver: none
  ###################################################################

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: ${ZOOKEEPER_PORT}
      ZOOKEEPER_TICK_TIME: ${ZOOKEPER_TICK_TIME}
    ports:
      - "${ZOOKEEPER_PORT}:${ZOOKEEPER_PORT}"
    networks:
      - net
    healthcheck:
      test:
        [
          "CMD",
          "echo",
          "ruok",
          "|",
          "nc",
          "localhost",
          "2181",
          "|",
          "grep",
          "imok",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
    logging:
      driver: none
  ########################## ############################# #############
  kafka:
    image: confluentinc/cp-kafka:latest
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:${ZOOKEEPER_PORT}"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:${LOCAL_KAFKA_PORT1},PLAINTEXT_HOST://kafka:${LOCAL_KAFKA_PORT2}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:${LOCAL_KAFKA_PORT1},PLAINTEXT_HOST://0.0.0.0:${LOCAL_KAFKA_PORT2}
      KAFKA_DELETE_TOPIC_ENABLE: "true"
      KAFKA_JMX_PORT: 9999
      KAFKA_JMX_HOSTNAME: "kafka"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_MESSAGE_MAX_BYTES: 200000000 # Increase max message size to 200 MB
      KAFKA_REPLICA_FETCH_MAX_BYTES: 200000000 # Increase fetch size to 200 MB
      CONNECT_MAX_REQUEST_SIZE: 200000000 # Increase request size to 200 MB
      CONNECT_PRODUCER_MAX_REQUEST_SIZE: 200000000 # Increase producer request size to 200 MB
      CONNECT_CONSUMER_MAX_FETCH_BYTES: 200000000 # Increase consumer fetch size to 200 MB
    ports:
      - "${HOST_KAFKA_PORT1}:${LOCAL_KAFKA_PORT1}"
      - "${HOST_KAFKA_PORT2}:${LOCAL_KAFKA_PORT2}"
    networks:
      - net
    depends_on:
      zookeeper:
        condition: service_healthy
  ###################################################################
  schema-registry:
    image: confluentinc/cp-schema-registry:latest
    container_name: schema-registry
    ports:
      - "${HOST_SCHEMA_REGISTRY_PORT}:${LOCAL_SCHMEA_REGISTRY_PORT}"
    depends_on:
      - zookeeper
      - kafka
    environment:
      SCHEMA_REGISTRY_HOST_NAME: ${SCHEMA_REGISTRY_HOST_NAME}
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: ${KAFKA_HOST_NAME}:${LOCAL_KAFKA_PORT2}
    networks:
      - net
  ###################################################################
  kafka-connect:
    image: confluentinc/cp-kafka-connect-base:6.2.0
    container_name: kafka-connect
    depends_on:
      - kafka
    ports:
      - 8085:8085
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:29092"
      CONNECT_REST_PORT: 8085
      CONNECT_GROUP_ID: kafka-connect
      CONNECT_CONFIG_STORAGE_TOPIC: _connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _connect-status
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      TIMESCALE_DATABASE: ${TIMESCALE_DATABASE}
      TIMESCALE_HOST_NAME: ${TIMESCALE_HOST_NAME}
      TIMESCALE_USER: ${TIMESCALE_USER}
      TIMESCALE_PASSWORD: ${TIMESCALE_PASSWORD}
      TIMESCALE_PORT: ${LOCAL_TIMESCALE_PORT}
      #  ---------------
      CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components,/data/connect-jars,/usr/share/custom-plugins
    volumes:
      - ./docker_init/kafka_init/connect-plugins:/usr/share/custom-plugins
      - ./docker_init/kafka_init/kafka-connect-configs/timescaledb-sink.json:/usr/share/connect-configs/timescaledb-sink.json
    command:
      - bash
      - -c
      - |
        echo "Launching Kafka Connect worker"

        sleep 10

        /etc/confluent/docker/run &

        echo "Waiting for Kafka Connect to start listening on 8085..."
        while ! nc -z localhost 8085; do
          sleep 1 # wait for 1 second before check again
        done

        sleep 10 # wait a bit for connectors to be installed and Kafka Connect to stabilize

        echo "Posting configuration to Kafka Connect"
        curl -X POST -H "Content-Type: application/json" --data @/usr/share/connect-configs/timescaledb-sink.json http://kafka-connect:8085/connectors

        sleep infinity

    networks:
      - net

  # ######################### END KAFKA ################################

  # ########################## REDIS ################################
  # # cryptic_redis:
  # #   image: redis:6
  # #   volumes:
  # #     - ./redis_data:/data
  # #   networks:
  # #     - cryptic_network
  # #   ports:
  # #     - "6379:6379"
  # # cryptic_redisinsight:
  # #   image: redislabs/redisinsight:latest
  # #   restart: unless-stopped
  # #   environment:
  # #     REDIS_1_HOST: cryptic_redis
  # #   networks:
  # #     - cryptic_network
  # #   ports:
  # #     - "8001:5540"
  # #   depends_on:
  # #     - cryptic_redis
  # ######################## END REDIS ################################

  ################################ SCRIPTS ################################
  crypto_live:
    build:
      context: ./crypto_live
      dockerfile: Dockerfile
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:${LOCAL_KAFKA_PORT1}
      SCHEMA_REGISTRY_URL: http://schema-registry:{LOCAL_SCHMEA_REGISTRY_PORT}
    depends_on:
      - kafka
      - zookeeper
      - schema-registry
    volumes:
      - ./crypto_live:/app

    networks:
      - net
  # logging:
  #   driver: none
  ###################################################################

  # forex_historic:
  #   build:
  #     context: ./forex_historic
  #     dockerfile: Dockerfile
  #   environment:
  #     PREFECT_API_URL: "http://cryptic_prefect_server:4200/api"
  #     PREFECT_HOST: "cryptic_prefect_server"
  #     PREFECT_PORT: "4200"
  #   networks:
  #     - cryptic_network
  #   depends_on:
  #     - postgres
  #     - cryptic_prefect_server
  #   volumes:
  #     - ./forex_historic:/app
  #   logging:
  #     driver: none
  crypto_historic:
    build:
      context: ./crypto_historic
      dockerfile: Dockerfile
    environment:
      PREFECT_API_URL: "http://perfect_server:4200/api"
      PREFECT_HOST: "perfect_server"
      PREFECT_PORT: "4200"
    networks:
      - net
    depends_on:
      - postgres
      - perfect_server
    volumes:
      - ./crypto_historic:/app
    logging:
      driver: none
networks:
  net:
    driver: bridge
